"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9465],{3905:function(e,t,a){a.d(t,{Zo:function(){return p},kt:function(){return h}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var m=n.createContext({}),d=function(e){var t=n.useContext(m),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=d(e.components);return n.createElement(m.Provider,{value:t},e.children)},s={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,m=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),u=d(a),h=r,k=u["".concat(m,".").concat(h)]||u[h]||s[h]||l;return a?n.createElement(k,i(i({ref:t},p),{},{components:a})):n.createElement(k,i({ref:t},p))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=u;var o={};for(var m in t)hasOwnProperty.call(t,m)&&(o[m]=t[m]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var d=2;d<l;d++)i[d]=a[d];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},9825:function(e,t,a){a.r(t),a.d(t,{assets:function(){return p},contentTitle:function(){return m},default:function(){return h},frontMatter:function(){return o},metadata:function(){return d},toc:function(){return s}});var n=a(7462),r=a(3366),l=(a(7294),a(3905)),i=["components"],o={sidebar_position:3,title:"Default Profiles"},m=void 0,d={unversionedId:"reference-manual/profiles",id:"reference-manual/profiles",title:"Default Profiles",description:"As you have seen from the previous tutorials, your systems are fully customizable in classy.",source:"@site/docs/reference-manual/profiles.md",sourceDirName:"reference-manual",slug:"/reference-manual/profiles",permalink:"/classy/docs/reference-manual/profiles",editUrl:"https://github.com/sunglasses-ai/classy/edit/main/docs/docs/reference-manual/profiles.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,title:"Default Profiles"},sidebar:"tutorialSidebar",previous:{title:"Tasks and Input Formats",permalink:"/classy/docs/reference-manual/tasks-and-formats"},next:{title:"Mixins",permalink:"/classy/docs/reference-manual/mixins"}},p={},s=[{value:"distilbert \ud83c\udf33 \ud83d\ude80",id:"distilbert--",level:2},{value:"General Info",id:"general-info",level:5},{value:"Model and Optimization",id:"model-and-optimization",level:5},{value:"Train command",id:"train-command",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile",level:5},{value:"distilroberta \ud83c\udf33 \ud83d\ude80",id:"distilroberta--",level:2},{value:"General Info",id:"general-info-1",level:5},{value:"Model and Optimization",id:"model-and-optimization-1",level:5},{value:"Train command",id:"train-command-1",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-1",level:5},{value:"squeezebert \ud83c\udf33 \ud83d\ude80",id:"squeezebert--",level:2},{value:"General Info",id:"general-info-2",level:5},{value:"Model and Optimization",id:"model-and-optimization-2",level:5},{value:"Train command",id:"train-command-2",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-2",level:5},{value:"bert-base \ud83c\udf32 \ud83d\ude84",id:"bert-base--",level:2},{value:"General Info",id:"general-info-3",level:5},{value:"Model and Optimization",id:"model-and-optimization-3",level:5},{value:"Train command",id:"train-command-3",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-3",level:5},{value:"gpt2 \ud83c\udf32 \ud83d\ude84",id:"gpt2--",level:2},{value:"General Info",id:"general-info-4",level:5},{value:"Model and Optimization",id:"model-and-optimization-4",level:5},{value:"Train command",id:"train-command-4",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-4",level:5},{value:"roberta-base \ud83c\udf32 \ud83d\ude84",id:"roberta-base--",level:2},{value:"General Info",id:"general-info-5",level:5},{value:"Model and Optimization",id:"model-and-optimization-5",level:5},{value:"Train command",id:"train-command-5",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-5",level:5},{value:"deberta-base \ud83c\udf32 \ud83d\ude84",id:"deberta-base--",level:2},{value:"General Info",id:"general-info-6",level:5},{value:"Model and Optimization",id:"model-and-optimization-6",level:5},{value:"Train command",id:"train-command-6",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-6",level:5},{value:"bart-base \ud83c\udf32 \ud83d\ude84",id:"bart-base--",level:2},{value:"General Info",id:"general-info-7",level:5},{value:"Model and Optimization",id:"model-and-optimization-7",level:5},{value:"Train command",id:"train-command-7",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-7",level:5},{value:"multilingual-bert \ud83c\udf32 \ud83d\ude84 \ud83c\udf0f",id:"multilingual-bert---",level:2},{value:"General Info",id:"general-info-8",level:5},{value:"Model and Optimization",id:"model-and-optimization-8",level:5},{value:"Train command",id:"train-command-8",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-8",level:5},{value:"xlm-roberta-base \ud83c\udf32 \ud83d\ude84 \ud83c\udf0f",id:"xlm-roberta-base---",level:2},{value:"General Info",id:"general-info-9",level:5},{value:"Model and Optimization",id:"model-and-optimization-9",level:5},{value:"Train command",id:"train-command-9",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-9",level:5},{value:"bert-large \ud83c\udf35 \ud83d\ude9c",id:"bert-large--",level:2},{value:"General Info",id:"general-info-10",level:5},{value:"Model and Optimization",id:"model-and-optimization-10",level:5},{value:"Train command",id:"train-command-10",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-10",level:5},{value:"roberta-large \ud83c\udf35 \ud83d\ude9c",id:"roberta-large--",level:2},{value:"General Info",id:"general-info-11",level:5},{value:"Model and Optimization",id:"model-and-optimization-11",level:5},{value:"Train command",id:"train-command-11",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-11",level:5},{value:"deberta-large \ud83c\udf35 \ud83d\ude9c",id:"deberta-large--",level:2},{value:"General Info",id:"general-info-12",level:5},{value:"Model and Optimization",id:"model-and-optimization-12",level:5},{value:"Train command",id:"train-command-12",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-12",level:5},{value:"xlm-roberta-large \ud83c\udf35 \ud83d\ude9c \ud83c\udf0f",id:"xlm-roberta-large---",level:2},{value:"General Info",id:"general-info-13",level:5},{value:"Model and Optimization",id:"model-and-optimization-13",level:5},{value:"Train command",id:"train-command-13",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-13",level:5},{value:"gpt2-medium \ud83c\udf35 \ud83d\ude9c",id:"gpt2-medium--",level:2},{value:"General Info",id:"general-info-14",level:5},{value:"Model and Optimization",id:"model-and-optimization-14",level:5},{value:"Train command",id:"train-command-14",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-14",level:5},{value:"bart-large \ud83c\udf35 \ud83d\ude9c",id:"bart-large--",level:2},{value:"General Info",id:"general-info-15",level:5},{value:"Model and Optimization",id:"model-and-optimization-15",level:5},{value:"Train command",id:"train-command-15",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-15",level:5},{value:"mbart \ud83c\udf35 \ud83c\udfd7\ufe0f \ud83c\udf0f",id:"mbart--\ufe0f-",level:2},{value:"General Info",id:"general-info-16",level:5},{value:"Model and Optimization",id:"model-and-optimization-16",level:5},{value:"Train command",id:"train-command-16",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-16",level:5},{value:"gpt2-large \ud83c\udf35 \ud83c\udfd7\ufe0f",id:"gpt2-large--\ufe0f",level:2},{value:"General Info",id:"general-info-17",level:5},{value:"Model and Optimization",id:"model-and-optimization-17",level:5},{value:"Train command",id:"train-command-17",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-17",level:5}],u={toc:s};function h(e){var t=e.components,a=(0,r.Z)(e,i);return(0,l.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("p",null,"As you have seen from the previous tutorials, your systems are fully customizable in ",(0,l.kt)("inlineCode",{parentName:"p"},"classy"),".\nEven if we strongly encourage you to create you own configurations, we provide a set of predefined and well-established profiles\nthat will work with competitive performances in almost all setting and scenarios."),(0,l.kt)("div",{className:"admonition admonition-tip alert alert--success"},(0,l.kt)("div",{parentName:"div",className:"admonition-heading"},(0,l.kt)("h5",{parentName:"div"},(0,l.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,l.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,l.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"tip")),(0,l.kt)("div",{parentName:"div",className:"admonition-content"},(0,l.kt)("p",{parentName:"div"},"To use a profile, you just have to pass the profile name to the parameter ",(0,l.kt)("inlineCode",{parentName:"p"},"--profile")," at training time"),(0,l.kt)("pre",{parentName:"div"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train <task> <dataset-path> -n <model-name> --profile <profile_name>\n")))),(0,l.kt)("h2",{id:"distilbert--"},"distilbert \ud83c\udf33 \ud83d\ude80"),(0,l.kt)("h5",{id:"general-info"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 4GB")))),(0,l.kt)("h5",{id:"model-and-optimization"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"DistilBERT")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1910.01108"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/distilbert.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"Adafactor")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1804.04235"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adafactor-pytorch"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile distilbert\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"blazing fast")," training and inference"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Quick run")," to evaluate your dataset and check for possible flaws"),(0,l.kt)("li",{parentName:"ul"},"You don't have at your disposal a GPU with more than 4GB VRAM"),(0,l.kt)("li",{parentName:"ul"},"You will use the model in ",(0,l.kt)("strong",{parentName:"li"},"low energy consumption")," scenarios")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"distilroberta--"},"distilroberta \ud83c\udf33 \ud83d\ude80"),(0,l.kt)("h5",{id:"general-info-1"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 4GB")))),(0,l.kt)("h5",{id:"model-and-optimization-1"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"DistilRoBERTa")," (\ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/distilroberta-base"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"Adafactor")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1804.04235"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adafactor-pytorch"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-1"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile distilroberta\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-1"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"blazing fast")," training and inference"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Quick run")," to evaluate your dataset and check for possible flaws"),(0,l.kt)("li",{parentName:"ul"},"You don't have at your disposal a GPU with more than 4GB VRAM"),(0,l.kt)("li",{parentName:"ul"},"You will use the model in ",(0,l.kt)("strong",{parentName:"li"},"low energy consumption")," scenarios")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"squeezebert--"},"squeezebert \ud83c\udf33 \ud83d\ude80"),(0,l.kt)("h5",{id:"general-info-2"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 4GB")))),(0,l.kt)("h5",{id:"model-and-optimization-2"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"SqueezeBERT")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/2006.11316"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/squeezebert.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"Adafactor")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1804.04235"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adafactor-pytorch"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-2"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile squeezebert\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-2"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"blazing fast")," training and inference"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Quick run")," to evaluate your dataset and check for possible flaws"),(0,l.kt)("li",{parentName:"ul"},"You don't have at your disposal a GPU with more than 4GB VRAM"),(0,l.kt)("li",{parentName:"ul"},"You will use the model in ",(0,l.kt)("strong",{parentName:"li"},"low energy consumption")," scenarios")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"bert-base--"},"bert-base \ud83c\udf32 \ud83d\ude84"),(0,l.kt)("h5",{id:"general-info-3"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,l.kt)("h5",{id:"model-and-optimization-3"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"BERT-base")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://aclanthology.org/N19-1423"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bert.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"AdamW")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-3"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile bert-base\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-3"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"well-established model")," for everyday use"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,l.kt)("li",{parentName:"ul"},"You will use the model in ",(0,l.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"gpt2--"},"gpt2 \ud83c\udf32 \ud83d\ude84"),(0,l.kt)("h5",{id:"general-info-4"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"generation")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,l.kt)("h5",{id:"model-and-optimization-4"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"GPT2")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/gpt2.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"Adam")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1412.6980"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.Adam.html"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-4"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [generation] my_dataset_path -n my_model --profile gpt2\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-4"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want an affordable (decoder-only) ",(0,l.kt)("strong",{parentName:"li"},"generative model")," for English"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,l.kt)("li",{parentName:"ul"},"You will use the model in ",(0,l.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"roberta-base--"},"roberta-base \ud83c\udf32 \ud83d\ude84"),(0,l.kt)("h5",{id:"general-info-5"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,l.kt)("h5",{id:"model-and-optimization-5"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"RoBERTa-base")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1907.11692"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bert.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"AdamW")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-5"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile bert-base\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-5"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"well-established model")," for everyday use"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,l.kt)("li",{parentName:"ul"},"You will use the model in ",(0,l.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"deberta-base--"},"deberta-base \ud83c\udf32 \ud83d\ude84"),(0,l.kt)("h5",{id:"general-info-6"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,l.kt)("h5",{id:"model-and-optimization-6"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"DeBERTa-base")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/2006.03654"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/deberta.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"RAdam")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/pdf/1908.03265v3.pdf"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://github.com/LiyuanLucasLiu/RAdam"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-6"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile deberta-base\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-6"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"recently released model with state-of-the-art performances")," on several NLU benchmarks"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,l.kt)("li",{parentName:"ul"},"You will use the model in ",(0,l.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"bart-base--"},"bart-base \ud83c\udf32 \ud83d\ude84"),(0,l.kt)("h5",{id:"general-info-7"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")," ",(0,l.kt)("inlineCode",{parentName:"td"},"generation")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,l.kt)("h5",{id:"model-and-optimization-7"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"Bart-base")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1910.13461"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bart.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"RAdam")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/pdf/1908.03265v3.pdf"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://github.com/LiyuanLucasLiu/RAdam"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-7"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa|generation] my_dataset_path -n my_model --profile bart-base\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-7"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,l.kt)("li",{parentName:"ul"},"You want to tackle an English generation task with an affordable model"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,l.kt)("li",{parentName:"ul"},"You will use the model in ",(0,l.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"multilingual-bert---"},"multilingual-bert \ud83c\udf32 \ud83d\ude84 \ud83c\udf0f"),(0,l.kt)("h5",{id:"general-info-8"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"104 (",(0,l.kt)("a",{parentName:"td",href:"https://github.com/google-research/bert/blob/master/multilingual.md"},"Complete List"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,l.kt)("h5",{id:"model-and-optimization-8"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"mBERT")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://aclanthology.org/N19-1423"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bert.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"AdamW")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-8"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile multilingual-bert\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-8"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You require a ",(0,l.kt)("strong",{parentName:"li"},"multilingual model")," covering languages other than English"),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"well-established model")," for everyday use"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,l.kt)("li",{parentName:"ul"},"You will use the model in ",(0,l.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"xlm-roberta-base---"},"xlm-roberta-base \ud83c\udf32 \ud83d\ude84 \ud83c\udf0f"),(0,l.kt)("h5",{id:"general-info-9"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"100 (Complete list in the reference paper)"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,l.kt)("h5",{id:"model-and-optimization-9"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"XLM-RoBERTa-base")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1911.02116"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/xlmroberta.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"AdamW")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-9"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile xlm-roberta-base\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-9"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You require a state-of-the-art ",(0,l.kt)("strong",{parentName:"li"},"multilingual model")," covering languages other than English"),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"well-established model")," for everyday use"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,l.kt)("li",{parentName:"ul"},"You will use the model in ",(0,l.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"bert-large--"},"bert-large \ud83c\udf35 \ud83d\ude9c"),(0,l.kt)("h5",{id:"general-info-10"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 11GB (fp16)")))),(0,l.kt)("h5",{id:"model-and-optimization-10"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"BERT-large")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://aclanthology.org/N19-1423"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bert.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"AdamW")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-10"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile bert-large --fp16\n")),(0,l.kt)("div",{className:"admonition admonition-caution alert alert--warning"},(0,l.kt)("div",{parentName:"div",className:"admonition-heading"},(0,l.kt)("h5",{parentName:"div"},(0,l.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,l.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"},(0,l.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"}))),"caution")),(0,l.kt)("div",{parentName:"div",className:"admonition-content"},(0,l.kt)("p",{parentName:"div"},"Remember to use the ",(0,l.kt)("inlineCode",{parentName:"p"},"--fp16")," at training time or otherwise the model may not fit in memory."))),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-10"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want state-of-the-art performances, ",(0,l.kt)("strong",{parentName:"li"},"no compromise!")),(0,l.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"well-established model")," used by thousands of users"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,l.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"roberta-large--"},"roberta-large \ud83c\udf35 \ud83d\ude9c"),(0,l.kt)("h5",{id:"general-info-11"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 11GB (fp16)")))),(0,l.kt)("h5",{id:"model-and-optimization-11"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"RoBERTa-large")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1907.11692"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bert.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"AdamW")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-11"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile roberta-large --fp16\n")),(0,l.kt)("div",{className:"admonition admonition-caution alert alert--warning"},(0,l.kt)("div",{parentName:"div",className:"admonition-heading"},(0,l.kt)("h5",{parentName:"div"},(0,l.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,l.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"},(0,l.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"}))),"caution")),(0,l.kt)("div",{parentName:"div",className:"admonition-content"},(0,l.kt)("p",{parentName:"div"},"Remember to use the ",(0,l.kt)("inlineCode",{parentName:"p"},"--fp16")," at training time or otherwise the model may not fit in memory."))),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-11"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want state-of-the-art performances, ",(0,l.kt)("strong",{parentName:"li"},"no compromise!")),(0,l.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"well-established model")," used by thousands of users"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,l.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"deberta-large--"},"deberta-large \ud83c\udf35 \ud83d\ude9c"),(0,l.kt)("h5",{id:"general-info-12"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 11GB (fp16)")))),(0,l.kt)("h5",{id:"model-and-optimization-12"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"DeBERTa-large")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/2006.03654"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/deberta.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"RAdam")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/pdf/1908.03265v3.pdf"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://github.com/LiyuanLucasLiu/RAdam"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-12"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile deberta-large --fp16\n")),(0,l.kt)("div",{className:"admonition admonition-caution alert alert--warning"},(0,l.kt)("div",{parentName:"div",className:"admonition-heading"},(0,l.kt)("h5",{parentName:"div"},(0,l.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,l.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"},(0,l.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"}))),"caution")),(0,l.kt)("div",{parentName:"div",className:"admonition-content"},(0,l.kt)("p",{parentName:"div"},"Remember to use the ",(0,l.kt)("inlineCode",{parentName:"p"},"--fp16")," at training time or otherwise the model may not fit in memory."))),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-12"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want state-of-the-art performances, ",(0,l.kt)("strong",{parentName:"li"},"no compromise!")),(0,l.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,l.kt)("li",{parentName:"ul"},"You want ",(0,l.kt)("strong",{parentName:"li"},"one of the latest released SotA models")),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,l.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"xlm-roberta-large---"},"xlm-roberta-large \ud83c\udf35 \ud83d\ude9c \ud83c\udf0f"),(0,l.kt)("h5",{id:"general-info-13"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")),(0,l.kt)("td",{parentName:"tr",align:"center"},"100 (Complete list in the reference paper)"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 16GB (fp16)")))),(0,l.kt)("h5",{id:"model-and-optimization-13"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"XLM-RoBERTa-large")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1911.02116"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/xlmroberta.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"AdamW")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-13"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile xlm-roberta-large --fp16\n")),(0,l.kt)("div",{className:"admonition admonition-caution alert alert--warning"},(0,l.kt)("div",{parentName:"div",className:"admonition-heading"},(0,l.kt)("h5",{parentName:"div"},(0,l.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,l.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"},(0,l.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"}))),"caution")),(0,l.kt)("div",{parentName:"div",className:"admonition-content"},(0,l.kt)("p",{parentName:"div"},"Remember to use the ",(0,l.kt)("inlineCode",{parentName:"p"},"--fp16")," at training time or otherwise the model may not fit in memory."))),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-13"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You require a state-of-the-art ",(0,l.kt)("strong",{parentName:"li"},"multilingual model")," covering languages other than English, with ",(0,l.kt)("strong",{parentName:"li"},"no compromise")),(0,l.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"well-established model")," used by thousands of users"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,l.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"gpt2-medium--"},"gpt2-medium \ud83c\udf35 \ud83d\ude9c"),(0,l.kt)("h5",{id:"general-info-14"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"generation")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 11GB (fp16)")))),(0,l.kt)("h5",{id:"model-and-optimization-14"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"GPT2")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/gpt2.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"AdamW")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-14"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [generation] my_dataset_path -n my_model --profile gpt2-medium\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-14"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want a medium (decoder-only) ",(0,l.kt)("strong",{parentName:"li"},"generative model")," for English"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,l.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"bart-large--"},"bart-large \ud83c\udf35 \ud83d\ude9c"),(0,l.kt)("h5",{id:"general-info-15"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")," ",(0,l.kt)("inlineCode",{parentName:"td"},"generation")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 11GB (fp16)")))),(0,l.kt)("h5",{id:"model-and-optimization-15"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"Bart-large")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1910.13461"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bart.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"RAdam")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/pdf/1908.03265v3.pdf"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://github.com/LiyuanLucasLiu/RAdam"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-15"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa|generation] my_dataset_path -n my_model --profile bart-large\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-15"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want state-of-the-art performances, especially on English generation problems, with ",(0,l.kt)("strong",{parentName:"li"},"no compromise!")),(0,l.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"well-established model")," used by thousands of users"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,l.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"mbart--\ufe0f-"},"mbart \ud83c\udf35 \ud83c\udfd7\ufe0f \ud83c\udf0f"),(0,l.kt)("h5",{id:"general-info-16"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,l.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,l.kt)("inlineCode",{parentName:"td"},"token")," ",(0,l.kt)("inlineCode",{parentName:"td"},"qa")," ",(0,l.kt)("inlineCode",{parentName:"td"},"generation")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 24GB (fp16)")))),(0,l.kt)("h5",{id:"model-and-optimization-16"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"mBART")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/2001.08210"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/mbart.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"RAdam")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/pdf/1908.03265v3.pdf"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://github.com/LiyuanLucasLiu/RAdam"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-16"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile bart-base\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-16"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want a state-of-the-art ",(0,l.kt)("strong",{parentName:"li"},"multilingual model"),", covering 25 languages and particularly suited for ",(0,l.kt)("strong",{parentName:"li"},"generation tasks")," (e.g. machine translation), with ",(0,l.kt)("strong",{parentName:"li"},"no compromise")),(0,l.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,l.kt)("li",{parentName:"ul"},"You want a ",(0,l.kt)("strong",{parentName:"li"},"well-established model")," used by thousands of users"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 24GB of VRAM that supports fp16 precision"),(0,l.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"gpt2-large--\ufe0f"},"gpt2-large \ud83c\udf35 \ud83c\udfd7\ufe0f"),(0,l.kt)("h5",{id:"general-info-17"},"General Info"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("inlineCode",{parentName:"td"},"generation")),(0,l.kt)("td",{parentName:"tr",align:"center"},"English"),(0,l.kt)("td",{parentName:"tr",align:"center"},"< 24GB (fp16)")))),(0,l.kt)("h5",{id:"model-and-optimization-17"},"Model and Optimization"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"GPT2")," (\ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"},"Paper")," ","|"," \ud83d\udd28 ",(0,l.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/gpt2.html"},"Implementation"),")"),(0,l.kt)("td",{parentName:"tr",align:"center"},(0,l.kt)("u",null,"AdamW")," (",(0,l.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,l.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,l.kt)("h5",{id:"train-command-17"},"Train command"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [generation] my_dataset_path -n my_model --profile gpt2-large\n")),(0,l.kt)("h5",{id:"when-should-i-use-this-profile-17"},"When should I use this profile?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"You want a large (decoder-only) ",(0,l.kt)("strong",{parentName:"li"},"generative model")," for English"),(0,l.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 24GB of VRAM that supports fp16 precision"),(0,l.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")))}h.isMDXComponent=!0}}]);